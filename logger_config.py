import logging
import logging.handlers
import os
import datetime
import gzip

LOG_DIR = 'logs'
LOG_FILE_PREFIX = 'paises_'

class IpFormatter(logging.Formatter):
    def format(self, record):
        if not hasattr(record, 'ip_address'):
            record.ip_address = 'N/A'
        return super().format(record)

def setup_logging():
    # Create logs directory if it doesn't exist
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

    log_file_path = os.path.join(LOG_DIR, f'{LOG_FILE_PREFIX}%Y%m%d.log')

    # Configure logging
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # Create a daily rotating file handler
    # 'midnight' means rotate at midnight, 1 means keep 1 backup (current day + 1 previous day)
    # The filename will be generated by TimedRotatingFileHandler based on the suffix
    handler = logging.handlers.TimedRotatingFileHandler(
        filename=os.path.join(LOG_DIR, LOG_FILE_PREFIX),
        when='midnight',
        interval=1,
        backupCount=30, # Keep logs for 30 days
        encoding='utf-8',
        atTime=datetime.time(0, 0, 0)
    )
    handler.suffix = "%Y-%m-%d.log"
    handler.setFormatter(IpFormatter('%(asctime)s - %(levelname)s - %(ip_address)s - %(message)s'))
    logger.addHandler(handler)

    # Add a console handler as well
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(IpFormatter('%(asctime)s - %(levelname)s - %(ip_address)s - %(message)s'))
    logger.addHandler(console_handler)

    return logger

def cleanup_old_logs():
    # Compress logs older than 7 days
    seven_days_ago = datetime.datetime.now() - datetime.timedelta(days=7)

    for filename in os.listdir(LOG_DIR):
        if filename.startswith(LOG_FILE_PREFIX) and filename.endswith('.log'):
            file_date_str = filename[len(LOG_FILE_PREFIX):-4] # Extract YYYY-MM-DD
            try:
                file_date = datetime.datetime.strptime(file_date_str, '%Y-%m-%d')
                if file_date < seven_days_ago:
                    file_path = os.path.join(LOG_DIR, filename)
                    compressed_file_path = file_path + '.gz'
                    
                    if not os.path.exists(compressed_file_path): # Avoid re-compressing
                        with open(file_path, 'rb') as f_in:
                            with gzip.open(compressed_file_path, 'wb') as f_out:
                                f_out.writelines(f_in)
                        os.remove(file_path) # Remove original log file
                        print(f"Compressed and removed old log: {filename}")
            except ValueError:
                # Ignore files that don't match the date format
                pass

if __name__ == '__main__':
    # Example usage:
    logger = setup_logging()
    logger.info("This is a test log message.")
    logger.warning("This is a warning.")
    cleanup_old_logs()
    print("Log setup and cleanup script executed.")
